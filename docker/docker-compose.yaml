version: "3.9"

volumes:
  kafka-data:
    driver: local

services:

  nginx:
    image: jc21/nginx-proxy-manager:latest
    container_name: reverse-proxy
    restart: unless-stopped
    ports:
      - "8080:80"    # access to proxy services
      - "81:81"      # web access
      # - "443:443"  # HTTPS (quando vuoi → attualmente NON usato)
    volumes:
      - ./npm/data:/data
      - ./npm/letsencrypt:/etc/letsencrypt

  kafka:
    image: confluentinc/cp-kafka:8.0.0
    hostname: kafka
    container_name: kafka
    restart: unless-stopped

    # Porte NON esposte all’host (Kafka accessibile solo da rete Docker)
    # ports:
    #   - "9092:9092"
    #   - "9091:9091"
    #   - "1234:1234"

    volumes:
      - kafka-data:/var/lib/kafka/data
      # Volume Prometheus NON usato
      # - ./kafka/prometheus:/opt/prometheus:Z

    environment:

      # Configurazione di un processo kafka con il ruolo di
      # broker e controller. Si definiscono due listeners,
      # uno per parlare con gli altri broker (PLAINTEXT),
      # l'altro per parlare con altri controller (CONTROLLER)
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: CONTROLLER://kafka:29093,PLAINTEXT://kafka:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:29093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092

      # Dato un topic, questo può avere da 1 ad N partizioni
      # Ogni partizione è il contenitore logico dei messaggi
      # inviati al topic. I messaggi sono salvati in formato
      # compresso utilizzando gzip.
      KAFKA_NUM_PARTITIONS: 12
      KAFKA_COMPRESSION_TYPE: gzip
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

      # Directory log custom NON usata (default Kafka)
      # KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'

      # Auto-create topic NON usato
      # KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'

      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk

      # JMX & Prometheus settings
      KAFKA_JMX_PORT: 9091
      KAFKA_JMX_HOSTNAME: kafka

  # Servizio HTTP che salva gli schema Avro/JSON/Protobuf in Kafka
  # Si collega al cluster Kafka come client ed espone un listener
  # a tutto il mondo sulla porta 8085
  schema-registry:
    image: confluentinc/cp-schema-registry:8.0.0
    hostname: schema-registry
    container_name: schema-registry
    restart: on-failure
    # Porta NON esposta all’host (accesso solo interno)
    # ports:
    #   - "8085:8085"
    depends_on:
      - kafka
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:29092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8085
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: INFO

  # Kafka Connect è un servizio che consente di eseguire dei connettori
  # ossia delle procedure standard per trasferire dati da/verso Kafka
  # in modo trasparente. Anch'esso è un client del cluster Kafka
  connect:
    image: cnfldemos/kafka-connect-datagen:0.6.7-8.0.0
    hostname: connect
    container_name: connect
    restart: on-failure
    depends_on:
      - kafka
      - schema-registry
    # Porta REST NON esposta all’host
    # ports:
    #   - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:29092
      CONNECT_REST_PORT: 8083
      CONNECT_REST_LISTENERS: http://0.0.0.0:8083
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: kafka-connect
      CONNECT_CONFIG_STORAGE_TOPIC: __connect-config
      CONNECT_OFFSET_STORAGE_TOPIC: __connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: __connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8085
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components

  akhq:
    image: tchiotludo/akhq:latest
    container_name: akhq
    restart: unless-stopped
    # Porta web AKHQ NON esposta all’host
    # ports:
    #   - "8080:8080"
    depends_on:
      - kafka
      - schema-registry
      - connect
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            local-cluster:
              properties:
                bootstrap.servers: kafka:29092
              schema-registry:
                url: http://schema-registry:8085
              connect:
                - name: connect
                  url: http://connect:8083

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: on-failure
    # Porta Prometheus NON esposta all’host
    # ports:
    #   - "9090:9090"
    volumes:
      - ./prometheus:/etc/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"

  kafka-exporter:
    image: danielqsj/kafka-exporter:latest
    container_name: kafka-exporter
    restart: on-failure
    depends_on:
      - kafka
    command:
      - "--kafka.server=kafka:29092"

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: on-failure
    # Porta Grafana NON esposta all’host
    # ports:
    #   - "3000:3000"
    depends_on:
      - prometheus
